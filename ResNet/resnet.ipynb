{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root = '../data',train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 32, shuffle=False, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform= transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frong','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inchannel, channel, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inchannel, channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channel)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "            \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 16\n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self.make_layer(BasicBlock, 16, 3)\n",
    "        self.layer2 = self.make_layer(BasicBlock, 32, 3, stride=2)\n",
    "        self.layer3 = self.make_layer(BasicBlock, 64, 3, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, channel, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel:\n",
    "            downsample = nn.Sequential(nn.Conv2d(self.inchannel, channel, kernel_size=1, stride=stride, bias=False),\n",
    "                                      nn.BatchNorm2d(channel),)\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(block(self.inchannel, channel, stride, downsample))\n",
    "        self.inchannel = channel\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inchannel, channel))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use  2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use \",torch.cuda.device_count(),\"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "    \n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.1, weight_decay= 0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    for batch_idx,(imgs, labels) in enumerate(trainloader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(imgs), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.data[0]))\n",
    "            \n",
    "    print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "        \n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    total_correct =  0\n",
    "    for i in range(10):\n",
    "        total_correct += 100*class_correct[i]/class_total[i]\n",
    "        print('Accuracy of %5s : %2d %%'%(classes[i], 100*class_correct[i]/class_total[i]))\n",
    "\n",
    "    print('Accuracy overall: %d' % (total_correct/10))\n",
    "    \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in testloader:\n",
    "            imgs,labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(imgs)\n",
    "            test_loss += criterion(outputs,labels).data[0]\n",
    "            pred = outputs.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsue/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.418133\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.668473\n",
      "Training finished\n",
      "Accuracy of plane : 23 %\n",
      "Accuracy of   car : 77 %\n",
      "Accuracy of  bird : 38 %\n",
      "Accuracy of   cat : 47 %\n",
      "Accuracy of  deer : 31 %\n",
      "Accuracy of   dog : 18 %\n",
      "Accuracy of frong : 64 %\n",
      "Accuracy of horse : 75 %\n",
      "Accuracy of  ship : 83 %\n",
      "Accuracy of truck : 57 %\n",
      "Accuracy overall: 51\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.322467\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.179480\n",
      "Training finished\n",
      "Accuracy of plane : 58 %\n",
      "Accuracy of   car : 82 %\n",
      "Accuracy of  bird : 51 %\n",
      "Accuracy of   cat : 45 %\n",
      "Accuracy of  deer : 57 %\n",
      "Accuracy of   dog : 44 %\n",
      "Accuracy of frong : 74 %\n",
      "Accuracy of horse : 80 %\n",
      "Accuracy of  ship : 84 %\n",
      "Accuracy of truck : 84 %\n",
      "Accuracy overall: 66\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.960593\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.090334\n",
      "Training finished\n",
      "Accuracy of plane : 59 %\n",
      "Accuracy of   car : 86 %\n",
      "Accuracy of  bird : 58 %\n",
      "Accuracy of   cat : 59 %\n",
      "Accuracy of  deer : 62 %\n",
      "Accuracy of   dog : 41 %\n",
      "Accuracy of frong : 71 %\n",
      "Accuracy of horse : 91 %\n",
      "Accuracy of  ship : 91 %\n",
      "Accuracy of truck : 87 %\n",
      "Accuracy overall: 71\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.699078\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.925712\n",
      "Training finished\n",
      "Accuracy of plane : 68 %\n",
      "Accuracy of   car : 83 %\n",
      "Accuracy of  bird : 53 %\n",
      "Accuracy of   cat : 65 %\n",
      "Accuracy of  deer : 69 %\n",
      "Accuracy of   dog : 29 %\n",
      "Accuracy of frong : 62 %\n",
      "Accuracy of horse : 92 %\n",
      "Accuracy of  ship : 93 %\n",
      "Accuracy of truck : 93 %\n",
      "Accuracy overall: 71\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.622336\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.807147\n",
      "Training finished\n",
      "Accuracy of plane : 72 %\n",
      "Accuracy of   car : 77 %\n",
      "Accuracy of  bird : 62 %\n",
      "Accuracy of   cat : 72 %\n",
      "Accuracy of  deer : 76 %\n",
      "Accuracy of   dog : 35 %\n",
      "Accuracy of frong : 71 %\n",
      "Accuracy of horse : 94 %\n",
      "Accuracy of  ship : 90 %\n",
      "Accuracy of truck : 94 %\n",
      "Accuracy overall: 74\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.484001\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.615633\n",
      "Training finished\n",
      "Accuracy of plane : 75 %\n",
      "Accuracy of   car : 81 %\n",
      "Accuracy of  bird : 67 %\n",
      "Accuracy of   cat : 69 %\n",
      "Accuracy of  deer : 76 %\n",
      "Accuracy of   dog : 53 %\n",
      "Accuracy of frong : 73 %\n",
      "Accuracy of horse : 95 %\n",
      "Accuracy of  ship : 85 %\n",
      "Accuracy of truck : 91 %\n",
      "Accuracy overall: 76\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.416002\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.560628\n",
      "Training finished\n",
      "Accuracy of plane : 80 %\n",
      "Accuracy of   car : 73 %\n",
      "Accuracy of  bird : 73 %\n",
      "Accuracy of   cat : 75 %\n",
      "Accuracy of  deer : 81 %\n",
      "Accuracy of   dog : 53 %\n",
      "Accuracy of frong : 52 %\n",
      "Accuracy of horse : 93 %\n",
      "Accuracy of  ship : 87 %\n",
      "Accuracy of truck : 91 %\n",
      "Accuracy overall: 76\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.378123\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.654362\n",
      "Training finished\n",
      "Accuracy of plane : 84 %\n",
      "Accuracy of   car : 77 %\n",
      "Accuracy of  bird : 75 %\n",
      "Accuracy of   cat : 71 %\n",
      "Accuracy of  deer : 72 %\n",
      "Accuracy of   dog : 54 %\n",
      "Accuracy of frong : 64 %\n",
      "Accuracy of horse : 93 %\n",
      "Accuracy of  ship : 84 %\n",
      "Accuracy of truck : 88 %\n",
      "Accuracy overall: 76\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.391437\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.577403\n",
      "Training finished\n",
      "Accuracy of plane : 76 %\n",
      "Accuracy of   car : 86 %\n",
      "Accuracy of  bird : 73 %\n",
      "Accuracy of   cat : 71 %\n",
      "Accuracy of  deer : 83 %\n",
      "Accuracy of   dog : 45 %\n",
      "Accuracy of frong : 65 %\n",
      "Accuracy of horse : 93 %\n",
      "Accuracy of  ship : 93 %\n",
      "Accuracy of truck : 83 %\n",
      "Accuracy overall: 77\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
