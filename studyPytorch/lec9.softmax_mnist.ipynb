{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../data/', train=True, transform= transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='../data/', train=False, transform= transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.L1 = nn.Linear(784, 520)\n",
    "        self.L2 = nn.Linear(520, 320)\n",
    "        self.L3 = nn.Linear(320, 240)\n",
    "        self.L4 = nn.Linear(240, 120)\n",
    "        self.L5 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.L1(x))\n",
    "        x = F.relu(self.L2(x))\n",
    "        x = F.relu(self.L3(x))\n",
    "        x = F.relu(self.L4(x))\n",
    "        return self.L5(x)\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data),Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss:{:.6f}'.format(epoch, batch_idx*len(data)\n",
    "                                                                           ,len(train_loader.dataset),\n",
    "                                                                          100.*batch_idx /len(train_loader),\n",
    "                                                                          loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True),Variable(target)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsue/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t Loss:2.302313\n",
      "Train Epoch: 1 [6400/60000 (11%)]\t Loss:2.299247\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t Loss:2.290041\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t Loss:2.300921\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t Loss:2.295409\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t Loss:2.280081\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t Loss:2.262786\n",
      "Train Epoch: 1 [44800/60000 (75%)]\t Loss:2.206924\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t Loss:2.086842\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t Loss:1.657949\n",
      "Train Epoch: 2 [0/60000 (0%)]\t Loss:1.547017\n",
      "Train Epoch: 2 [6400/60000 (11%)]\t Loss:1.145486\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t Loss:0.998540\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t Loss:0.654078\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t Loss:0.585317\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t Loss:0.655989\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t Loss:0.429679\n",
      "Train Epoch: 2 [44800/60000 (75%)]\t Loss:0.366931\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t Loss:0.450511\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t Loss:0.536278\n",
      "Train Epoch: 3 [0/60000 (0%)]\t Loss:0.447764\n",
      "Train Epoch: 3 [6400/60000 (11%)]\t Loss:0.340345\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t Loss:0.415283\n",
      "Train Epoch: 3 [19200/60000 (32%)]\t Loss:0.533737\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t Loss:0.416949\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t Loss:0.271707\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t Loss:0.196659\n",
      "Train Epoch: 3 [44800/60000 (75%)]\t Loss:0.203725\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t Loss:0.241293\n",
      "Train Epoch: 3 [57600/60000 (96%)]\t Loss:0.249159\n",
      "Train Epoch: 4 [0/60000 (0%)]\t Loss:0.341072\n",
      "Train Epoch: 4 [6400/60000 (11%)]\t Loss:0.293521\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t Loss:0.184139\n",
      "Train Epoch: 4 [19200/60000 (32%)]\t Loss:0.256299\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t Loss:0.224940\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t Loss:0.217680\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t Loss:0.343397\n",
      "Train Epoch: 4 [44800/60000 (75%)]\t Loss:0.461270\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t Loss:0.144840\n",
      "Train Epoch: 4 [57600/60000 (96%)]\t Loss:0.135477\n",
      "Train Epoch: 5 [0/60000 (0%)]\t Loss:0.197076\n",
      "Train Epoch: 5 [6400/60000 (11%)]\t Loss:0.310358\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t Loss:0.190417\n",
      "Train Epoch: 5 [19200/60000 (32%)]\t Loss:0.140676\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t Loss:0.043288\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t Loss:0.186552\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t Loss:0.187330\n",
      "Train Epoch: 5 [44800/60000 (75%)]\t Loss:0.365736\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t Loss:0.159335\n",
      "Train Epoch: 5 [57600/60000 (96%)]\t Loss:0.189884\n",
      "Train Epoch: 6 [0/60000 (0%)]\t Loss:0.210114\n",
      "Train Epoch: 6 [6400/60000 (11%)]\t Loss:0.114830\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t Loss:0.096440\n",
      "Train Epoch: 6 [19200/60000 (32%)]\t Loss:0.169190\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t Loss:0.077473\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t Loss:0.054204\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t Loss:0.051882\n",
      "Train Epoch: 6 [44800/60000 (75%)]\t Loss:0.131552\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t Loss:0.125871\n",
      "Train Epoch: 6 [57600/60000 (96%)]\t Loss:0.133985\n",
      "Train Epoch: 7 [0/60000 (0%)]\t Loss:0.133553\n",
      "Train Epoch: 7 [6400/60000 (11%)]\t Loss:0.048742\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t Loss:0.203941\n",
      "Train Epoch: 7 [19200/60000 (32%)]\t Loss:0.148642\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t Loss:0.176240\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t Loss:0.107695\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t Loss:0.110723\n",
      "Train Epoch: 7 [44800/60000 (75%)]\t Loss:0.133600\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t Loss:0.135519\n",
      "Train Epoch: 7 [57600/60000 (96%)]\t Loss:0.091084\n",
      "Train Epoch: 8 [0/60000 (0%)]\t Loss:0.053745\n",
      "Train Epoch: 8 [6400/60000 (11%)]\t Loss:0.174950\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t Loss:0.118926\n",
      "Train Epoch: 8 [19200/60000 (32%)]\t Loss:0.213198\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t Loss:0.173378\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t Loss:0.028176\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t Loss:0.253756\n",
      "Train Epoch: 8 [44800/60000 (75%)]\t Loss:0.067523\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t Loss:0.078891\n",
      "Train Epoch: 8 [57600/60000 (96%)]\t Loss:0.200589\n",
      "Train Epoch: 9 [0/60000 (0%)]\t Loss:0.064174\n",
      "Train Epoch: 9 [6400/60000 (11%)]\t Loss:0.041723\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t Loss:0.110109\n",
      "Train Epoch: 9 [19200/60000 (32%)]\t Loss:0.125090\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t Loss:0.052156\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t Loss:0.161287\n",
      "Train Epoch: 9 [38400/60000 (64%)]\t Loss:0.019369\n",
      "Train Epoch: 9 [44800/60000 (75%)]\t Loss:0.216788\n",
      "Train Epoch: 9 [51200/60000 (85%)]\t Loss:0.014355\n",
      "Train Epoch: 9 [57600/60000 (96%)]\t Loss:0.097731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsue/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "/home/hsue/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9665/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
